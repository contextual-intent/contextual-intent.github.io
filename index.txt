2:I[2972,["674","static/chunks/ca377847-7e987621759529a8.js","651","static/chunks/7a49ec60-358c752022298c41.js","233","static/chunks/233-e3246d4cf323f42c.js","343","static/chunks/343-a9086327813d0eea.js","931","static/chunks/app/page-78460eec5d8b1c74.js"],""]
3:I[5390,["674","static/chunks/ca377847-7e987621759529a8.js","651","static/chunks/7a49ec60-358c752022298c41.js","233","static/chunks/233-e3246d4cf323f42c.js","343","static/chunks/343-a9086327813d0eea.js","931","static/chunks/app/page-78460eec5d8b1c74.js"],"default"]
4:I[190,["674","static/chunks/ca377847-7e987621759529a8.js","651","static/chunks/7a49ec60-358c752022298c41.js","233","static/chunks/233-e3246d4cf323f42c.js","343","static/chunks/343-a9086327813d0eea.js","931","static/chunks/app/page-78460eec5d8b1c74.js"],"default"]
5:I[282,["674","static/chunks/ca377847-7e987621759529a8.js","651","static/chunks/7a49ec60-358c752022298c41.js","233","static/chunks/233-e3246d4cf323f42c.js","343","static/chunks/343-a9086327813d0eea.js","931","static/chunks/app/page-78460eec5d8b1c74.js"],"default"]
6:I[2343,["233","static/chunks/233-e3246d4cf323f42c.js","185","static/chunks/app/layout-8cfbc9894cc7529e.js"],"default"]
7:I[4707,[],""]
8:I[6423,[],""]
0:["WcPR8yLtbRr_5l_M8y0wI",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1",["$","main",null,{"className":"min-h-screen pt-16 md:pt-20","children":[["$","section",null,{"className":"relative w-full min-h-screen flex items-center justify-center bg-gradient-to-br from-blue-50 via-white to-purple-50","children":["$","div",null,{"className":"container mx-auto px-4 sm:px-6 lg:px-8 py-20","children":[["$","div",null,{"className":"max-w-5xl mx-auto text-center","children":[["$","h1",null,{"className":"text-4xl sm:text-5xl md:text-6xl lg:text-7xl font-bold text-gray-900 mb-6 leading-tight","children":"Grounding Agent Memory in Contextual Intent"}],["$","div",null,{"className":"mb-6","children":["$","div",null,{"className":"flex flex-wrap justify-center items-center gap-x-4 gap-y-2 text-lg md:text-xl font-semibold text-gray-900","children":[["$","a","0",{"href":"https://www.linkedin.com/in/ruozhen-yang/","target":"_blank","rel":"noopener noreferrer","className":"hover:text-blue-600 transition-colors","children":"Ruozhen Yang"}],["$","a","1",{"href":"https://cs.stanford.edu/~yuchengj/","target":"_blank","rel":"noopener noreferrer","className":"hover:text-blue-600 transition-colors","children":"Yucheng Jiang"}],["$","a","2",{"href":"https://www.linkedin.com/in/yueqijiang/","target":"_blank","rel":"noopener noreferrer","className":"hover:text-blue-600 transition-colors","children":"Yueqi Jiang"}],["$","a","3",{"href":"https://pkargupta.github.io","target":"_blank","rel":"noopener noreferrer","className":"hover:text-blue-600 transition-colors","children":"Priyanka Kargupta"}],["$","a","4",{"href":"https://yzhan238.github.io","target":"_blank","rel":"noopener noreferrer","className":"hover:text-blue-600 transition-colors","children":"Yunyi Zhang"}],["$","a","5",{"href":"http://hanj.cs.illinois.edu","target":"_blank","rel":"noopener noreferrer","className":"hover:text-blue-600 transition-colors","children":"Jiawei Han"}]]}]}],["$","div",null,{"className":"flex flex-col sm:flex-row gap-4 justify-center items-center mt-12 flex-wrap","children":[["$","$L2",null,{"href":"https://arxiv.org/abs/2601.10702","target":"_blank","rel":"noopener noreferrer","className":"px-6 py-3 bg-white text-[#B31B1B] border-2 border-[#B31B1B] rounded-lg font-semibold text-lg hover:bg-red-50 transition-colors shadow-lg hover:shadow-xl flex items-center gap-2","children":[["$","svg",null,{"className":"w-5 h-5","viewBox":"0 0 17.732 24.269","xmlns":"http://www.w3.org/2000/svg","role":"img","aria-label":"arXiv Logo","children":["$","g",null,{"children":[["$","path",null,{"d":"M573.549,280.916l2.266,2.738,6.674-7.84c.353-.47.52-.717.353-1.117a1.218,1.218,0,0,0-1.061-.748h0a.953.953,0,0,0-.712.262Z","transform":"translate(-566.984 -271.548)","fill":"currentColor"}],["$","path",null,{"d":"M579.525,282.225l-10.606-10.174a1.413,1.413,0,0,0-.834-.5,1.09,1.09,0,0,0-1.027.66c-.167.4-.047.681.319,1.206l8.44,10.242h0l-6.282,7.716a1.336,1.336,0,0,0-.323,1.3,1.114,1.114,0,0,0,1.04.69A.992.992,0,0,0,571,293l8.519-7.92A1.924,1.924,0,0,0,579.525,282.225Z","transform":"translate(-566.984 -271.548)","fill":"currentColor"}],["$","path",null,{"d":"M584.32,293.912l-8.525-10.275,0,0L573.53,280.9l-1.389,1.254a2.063,2.063,0,0,0,0,2.965l10.812,10.419a.925.925,0,0,0,.742.282,1.039,1.039,0,0,0,.953-.667A1.261,1.261,0,0,0,584.32,293.912Z","transform":"translate(-566.984 -271.548)","fill":"currentColor"}]]}]}],"Paper"]}],["$","$L2",null,{"href":"https://github.com/dmg-lab/stitch","target":"_blank","rel":"noopener noreferrer","className":"px-6 py-3 bg-gray-900 text-white rounded-lg font-semibold text-lg hover:bg-gray-800 transition-colors shadow-lg hover:shadow-xl flex items-center gap-2","children":[["$","svg",null,{"className":"w-5 h-5","fill":"currentColor","viewBox":"0 0 24 24","aria-hidden":"true","children":["$","path",null,{"fillRule":"evenodd","d":"M12 2C6.477 2 2 6.484 2 12.017c0 4.425 2.865 8.18 6.839 9.504.5.092.682-.217.682-.483 0-.237-.008-.868-.013-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.029-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.844c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.027 2.747-1.027.546 1.379.202 2.398.1 2.651.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.019 10.019 0 0022 12.017C22 6.484 17.522 2 12 2z","clipRule":"evenodd"}]}],"Code"]}],["$","$L2",null,{"href":"https://huggingface.co/datasets/Seattleyrz/CAME-Bench","target":"_blank","rel":"noopener noreferrer","className":"px-6 py-3 bg-[#FFD21E] text-gray-900 rounded-lg font-semibold text-lg hover:bg-[#F5C518] transition-colors shadow-lg hover:shadow-xl flex items-center gap-2","children":[["$","span",null,{"className":"text-xl","children":"ü§ó"}],"Benchmark Data"]}],["$","$L2",null,{"href":"#abstract","className":"px-6 py-3 bg-white text-blue-600 border-2 border-blue-600 rounded-lg font-semibold text-lg hover:bg-blue-50 transition-colors flex items-center gap-2","children":"Learn More"}]]}]]}],["$","div",null,{"className":"mt-16 max-w-4xl mx-auto","children":["$","div",null,{"className":"relative w-full rounded-lg overflow-hidden shadow-2xl bg-transparent","children":["$","$L3",null,{"src":"/images/stitch_web_main.pdf","alt":"Project Overview","className":"object-contain"}]}]}]]}]}],["$","section",null,{"id":"abstract","className":"py-20 bg-white scroll-mt-16 md:scroll-mt-20","children":["$","div",null,{"className":"container mx-auto px-4 sm:px-6 lg:px-8","children":["$","div",null,{"className":"max-w-5xl mx-auto","children":[["$","h2",null,{"className":"text-4xl font-bold text-gray-900 mb-8","children":"Abstract"}],["$","div",null,{"className":"prose prose-lg max-w-none text-gray-700 leading-relaxed","children":[["$","p",null,{"className":"mb-6","children":["Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose ",["$","strong",null,{"className":"text-blue-600","children":"STITCH"}]," (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrieval cue, contextual intent, and retrieves history by matching the current step‚Äôs intent. Contextual intent provides compact signals that disambiguate repeated mentions and reduce interference: (1) the current latent goal defining a thematic segment, (2) the action type, and (3) the salient entity types anchoring which attributes matter. During inference, STITCH filters and prioritizes memory snippets by intent compatibility, suppressing semantically similar but context-incompatible history."]}],["$","p",null,{"className":"mb-6","children":["For evaluation, we introduce ",["$","strong",null,{"className":"text-blue-600","children":"CAME-Bench"}],", a benchmark for context-aware retrieval in realistic, dynamic, goal-oriented trajectories. Across CAME-Bench and LongMemEval, STITCH achieves state-of-the-art performance, outperforming the strongest baseline by 35.6%, with the largest gains as trajectory length increases. Our analysis shows that intent indexing substantially reduces retrieval noise, supporting intent-aware memory for robust long-horizon reasoning."]}]]}]]}]}]}],["$","section",null,{"id":"findings","className":"py-20 bg-gray-50 scroll-mt-16 md:scroll-mt-20","children":["$","div",null,{"className":"container mx-auto px-4 sm:px-6 lg:px-8","children":["$","div",null,{"className":"max-w-6xl mx-auto","children":[["$","h2",null,{"className":"text-4xl font-bold text-gray-900 mb-12 text-center","children":"Key Findings"}],["$","div",null,{"className":"grid grid-cols-1 md:grid-cols-2 gap-8 mb-12","children":[["$","div","1",{"className":"bg-white p-8 rounded-lg shadow-md hover:shadow-xl hover:-translate-y-1 transition-all duration-300","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"flex-shrink-0 w-12 h-12 bg-gray-900 text-white rounded-full flex items-center justify-center font-bold text-xl shadow-sm","children":"1"}],["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 mb-3","children":"State-of-the-Art Performance"}],["$","p",null,{"className":"text-gray-700 leading-relaxed","children":"STITCH consistently outperforms 13 strong baselines‚Äîincluding long-context LLMs (GPT-4.1-mini, GPT-5-mini) and structured memory systems (GraphRAG, RAPTOR)‚Äîacross both CAME-Bench and LongMemEval benchmarks."}]]}]]}]}],["$","div","2",{"className":"bg-white p-8 rounded-lg shadow-md hover:shadow-xl hover:-translate-y-1 transition-all duration-300","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"flex-shrink-0 w-12 h-12 bg-gray-900 text-white rounded-full flex items-center justify-center font-bold text-xl shadow-sm","children":"2"}],["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 mb-3","children":"Scales to Long Horizons"}],["$","p",null,{"className":"text-gray-700 leading-relaxed","children":"While standard baselines degrade as trajectory length increases, STITCH remains robust. On the 'Large' subset (~408k tokens), it outperforms the strongest baseline by 35.6%, eliminating the 'lost-in-the-middle' phenomenon."}]]}]]}]}],["$","div","3",{"className":"bg-white p-8 rounded-lg shadow-md hover:shadow-xl hover:-translate-y-1 transition-all duration-300","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"flex-shrink-0 w-12 h-12 bg-gray-900 text-white rounded-full flex items-center justify-center font-bold text-xl shadow-sm","children":"3"}],["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 mb-3","children":"Eliminates Retrieval Noise"}],["$","p",null,{"className":"text-gray-700 leading-relaxed","children":"By indexing steps with Contextual Intent, STITCH suppresses 'distractors'‚Äîevidence that is semantically similar but belongs to a different goal or time‚Äîensuring the agent retrieves the right fact in the right context."}]]}]]}]}],["$","div","4",{"className":"bg-white p-8 rounded-lg shadow-md hover:shadow-xl hover:-translate-y-1 transition-all duration-300","children":["$","div",null,{"className":"flex items-start gap-4","children":[["$","div",null,{"className":"flex-shrink-0 w-12 h-12 bg-gray-900 text-white rounded-full flex items-center justify-center font-bold text-xl shadow-sm","children":"4"}],["$","div",null,{"children":[["$","h3",null,{"className":"text-xl font-semibold text-gray-900 mb-3","children":"Thematic Scope is Critical"}],["$","p",null,{"className":"text-gray-700 leading-relaxed","children":"Ablation studies reveal that 'Thematic Scope' (goal-oriented segmentation) provides the largest performance gain, effectively partitioning long interaction histories into manageable, coherent episodes."}]]}]]}]}]]}],["$","div",null,{"className":"mt-12 w-full","children":["$","$L4",null,{}]}]]}]}]}],["$","section",null,{"id":"methodology","className":"py-20 bg-white scroll-mt-16 md:scroll-mt-20","children":["$","div",null,{"className":"container mx-auto px-4 sm:px-6 lg:px-8","children":["$","div",null,{"className":"max-w-5xl mx-auto","children":[["$","h2",null,{"className":"text-4xl font-bold text-gray-900 mb-12","children":"Methodology (STITCH)"}],["$","div",null,{"className":"space-y-16","children":[["$","div",null,{"children":[["$","p",null,{"className":"text-gray-700 leading-relaxed mb-6","children":["Standard retrieval relies on semantic similarity, which fails when similar facts recur in different contexts.",["$","span",null,{"className":"font-semibold","children":" STITCH"}]," (Structured Intent Tracking in Contextual History) solves this by indexing every trajectory step with a structured retrieval cue called ",["$","span",null,{"className":"font-semibold","children":"Contextual Intent"}],". Grounded in Event Structure Theory, STITCH organizes memory not as a flat list, but as a structured history of goals, actions, and entities."]}],["$","div",null,{"className":"mb-6","children":[["$","h4",null,{"className":"text-xl font-semibold text-gray-900 mb-4","children":"Core Concepts"}],["$","div",null,{"className":"space-y-4","children":[["$","div",null,{"className":"bg-blue-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"The Schema: Contextual Intent"}],["$","p",null,{"className":"text-gray-700","children":["We index each step with a tuple ",["$","span",null,{"className":"font-mono","children":"Œπt = (œÉt, œµt, Œ∫t)"}],":",["$","span",null,{"className":"block mt-2","children":["‚Ä¢ ",["$","span",null,{"className":"font-semibold","children":"Thematic Scope (Partonomy):"}]," A stable label tracking the current high-level goal (e.g., ‚ÄúDay 2 Itinerary‚Äù).",["$","br",null,{}],"‚Ä¢ ",["$","span",null,{"className":"font-semibold","children":"Event Type (Taxonomy):"}]," An action label capturing the operation performed (e.g., ‚ÄúComparison‚Äù, ‚ÄúDebugging‚Äù).",["$","br",null,{}],"‚Ä¢ ",["$","span",null,{"className":"font-semibold","children":"Key Entity Types (Taxonomy):"}]," The schema class identifying relevant attributes (e.g., ‚ÄúPrice‚Äù, ‚ÄúError Code‚Äù)."]}]]}]]}],["$","div",null,{"className":"bg-purple-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"Online Induction (Domain Agnostic)"}],["$","p",null,{"className":"text-gray-700","children":["STITCH does not require a pre-defined ontology. It induces these cues ",["$","strong",null,{"children":"online"}]," from the streaming trajectory. It uses sliding windows to detect goal shifts and maintains dynamic vocabularies for event and entity types that evolve as the agent encounters new tasks."]}]]}],["$","div",null,{"className":"bg-green-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"Structural Coreference Resolution"}],["$","p",null,{"className":"text-gray-700","children":["Implicit references are a major cause of retrieval failure. STITCH leverages the induced structure to resolve references",["$","em",null,{"children":"before"}]," storage. For example, an ambiguous step like ",["$","span",null,{"className":"italic","children":"\"Book it\""}]," is rewritten to ",["$","span",null,{"className":"font-semibold","children":"\"Book the Apollo Hotel\""}]," by aligning it with the active thematic scope."]}]]}],["$","div",null,{"className":"bg-slate-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300 border border-slate-200","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"Retrieval: Structure First, Semantics Second"}],["$","p",null,{"className":"text-gray-700","children":["At inference time, STITCH translates a query into a structured filter. We employ ",["$","strong",null,{"children":"Label Density Ranking"}],", which strictly prioritizes memory snippets that match the ",["$","em",null,{"children":"intent structure"}]," first. Semantic similarity is used only as a tie-breaker, effectively filtering out contextually irrelevant distractors."]}]]}]]}]]}],["$","div",null,{"className":"mt-8","children":[["$","h4",null,{"className":"text-xl font-semibold text-gray-900 mb-4","children":"System Architecture"}],["$","div",null,{"className":"relative w-full rounded-lg overflow-hidden shadow-lg bg-transparent","children":["$","$L5",null,{"src":"/images/method_figure.jpg","alt":"STITCH Overview - Contextual Intent Construction and Intent-Aware Retrieval","placeholder":"[Architecture Diagram: Construction Phase vs. Retrieval Phase]","width":1200,"height":900,"className":"w-full h-auto"}]}]]}]]}],["$","div",null,{"id":"benchmark","className":"scroll-mt-16 md:scroll-mt-20","children":[["$","div",null,{"className":"flex flex-col gap-4 sm:flex-row sm:items-center sm:justify-between mb-6","children":[["$","h3",null,{"className":"text-3xl font-semibold text-gray-900","children":"The Benchmark: CAME-Bench"}],["$","a",null,{"href":"/visualizer","className":"inline-flex items-center justify-center rounded-lg bg-gray-900 px-6 py-3 text-sm font-semibold text-white hover:bg-gray-800 transition-colors shadow-md hover:shadow-lg","children":"Open Benchmark Explorer ‚Üí"}]]}],["$","p",null,{"className":"text-gray-700 leading-relaxed mb-6","children":["Existing benchmarks often rely on unrealistic turn-taking or independent topics. To rigorously test context-aware retrieval, we introduce ",["$","strong",null,{"className":"text-blue-600","children":"CAME-Bench"}],". It features continuous, goal-oriented trajectories constructed with ",["$","strong",null,{"children":"High Contextual Interference"}],"‚Äîwhere recurring entities and interleaved goals create significant ambiguity."]}],["$","div",null,{"className":"mb-6","children":[["$","h4",null,{"className":"text-xl font-semibold text-gray-900 mb-4","children":"Design Principles"}],["$","div",null,{"className":"space-y-4","children":[["$","div",null,{"className":"bg-orange-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"Symbolically Grounded Consistency"}],["$","p",null,{"className":"text-gray-700","children":["We decouple planning from generation. A symbolic planner ensures logical causal consistency over long horizons (e.g., ",["$","span",null,{"className":"font-semibold","children":"Travel Planning"}]," itineraries and ",["$","span",null,{"className":"font-semibold","children":"Debate"}]," argumentation), guaranteeing that every state transition is valid before it is rendered into natural language."]}]]}],["$","div",null,{"className":"bg-yellow-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"Controlled Semantic Interference"}],["$","p",null,{"className":"text-gray-700","children":["We utilize a closed-world environment to ",["$","strong",null,{"children":"densely reuse static entities"}],". This forces models to disambiguate fine-grained context (e.g., the same hotel appearing in three different potential plans) rather than relying on unique keywords."]}]]}],["$","div",null,{"className":"bg-pink-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"Dynamic Referential Ambiguity"}],["$","p",null,{"className":"text-gray-700","children":"Interactions are not strictly turn-taking. Requests are often interleaved, deferred, or implicitly referenced later (e.g., \"Use the evidence from that previous counter-argument\"), requiring the memory system to track state updates rather than static facts."}]]}]]}]]}],["$","div",null,{"className":"mt-10","children":[["$","h4",null,{"className":"text-xl font-semibold text-gray-900 mb-4","children":"Evaluation Capabilities"}],["$","p",null,{"className":"text-gray-700 leading-relaxed mb-6","children":"We evaluate four distinct capabilities required for robust long-horizon agents:"}],["$","div",null,{"className":"grid grid-cols-1 md:grid-cols-2 gap-4","children":[["$","div",null,{"className":"bg-slate-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300 border border-slate-200","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"1. Incremental Memory Revision"}],["$","p",null,{"className":"text-gray-700 text-sm","children":["Can the agent track state changes? ",["$","br",null,{}],["$","em",null,{"children":"Ex: Tracking a restaurant candidate list as items are added and subsequently rejected across turns."}]]}]]}],["$","div",null,{"className":"bg-slate-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300 border border-slate-200","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"2. Context-Aware Factual Recall"}],["$","p",null,{"className":"text-gray-700 text-sm","children":["Can the agent disambiguate similar facts? ",["$","br",null,{}],["$","em",null,{"children":"Ex: Retrieving the hotel price specifically for \"Day 2\", distinguishing it from the \"Day 1\" price."}]]}]]}],["$","div",null,{"className":"bg-slate-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300 border border-slate-200","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"3. Multi-Hop Reasoning"}],["$","p",null,{"className":"text-gray-700 text-sm","children":["Can the agent resolve implicit references? ",["$","br",null,{}],["$","em",null,{"children":"Ex: Identifying what \"that reservation\" refers to, then retrieving its associated attributes."}]]}]]}],["$","div",null,{"className":"bg-slate-50 p-6 rounded-lg hover:shadow-lg hover:-translate-y-1 transition-all duration-300 border border-slate-200","children":[["$","h5",null,{"className":"font-semibold text-gray-900 mb-2","children":"4. Information Synthesis"}],["$","p",null,{"className":"text-gray-700 text-sm","children":["Can the agent aggregate scattered info? ",["$","br",null,{}],["$","em",null,{"children":"Ex: Reconstructing a full 3-day itinerary from bookings scattered across 500 turns of dialogue."}]]}]]}]]}]]}]]}]]}]]}]}]}]]}],[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/eee61b64c3c37e41.css","precedence":"next","crossOrigin":"$undefined"}]]],null],null]},[[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/c919b64b86bf3c48.css","precedence":"next","crossOrigin":"$undefined"}]],["$","html",null,{"lang":"en","children":["$","body",null,{"children":[["$","$L6",null,{}],["$","$L7",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L8",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[]}]]}]}]],null],null],["$L9",null]]]]
9:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Grounding Agent Memory in Contextual Intent"}],["$","meta","3",{"name":"description","content":"Research paper on STITCH: A system for grounding agent memory in contextual intent using structured retrieval cues and intent indexing."}],["$","meta","4",{"name":"author","content":"Research Team"}],["$","meta","5",{"name":"keywords","content":"AI,LLM,Agent Memory,Contextual Intent,STITCH,CAME-Bench"}],["$","meta","6",{"property":"og:title","content":"Grounding Agent Memory in Contextual Intent"}],["$","meta","7",{"property":"og:description","content":"Research paper on STITCH: A system for grounding agent memory in contextual intent"}],["$","meta","8",{"property":"og:type","content":"website"}],["$","meta","9",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","10",{"name":"twitter:title","content":"Grounding Agent Memory in Contextual Intent"}],["$","meta","11",{"name":"twitter:description","content":"Research paper on STITCH: A system for grounding agent memory in contextual intent"}]]
1:null
